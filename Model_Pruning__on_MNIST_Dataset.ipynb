{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Pruning__on_MNIST_Dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujjwaltyagi355/Machine-learning/blob/master/Model_Pruning__on_MNIST_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie7CeS0tTMss",
        "colab_type": "text"
      },
      "source": [
        "##Model Pruning On MNIST Dataset:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_uOjUo4TfzK",
        "colab_type": "text"
      },
      "source": [
        "With the ever evolving technological sphere and with bigger and bigger models being proposed to increase the accuracy or performance of the currently available models, the need to reduce the data and computational cost needs a direction. And with model pruning we can achieve this.\n",
        "The most comman type of model pruning is Weight pruning which can be employed by reducing the less useful weights from the trained model(or in some cases where random weights are initialised at the start).\n",
        "Such that number of parameters to be used becomes less, and hence the computational cost becomes less, the model size(with respect to the memory it takes) decreases, which minor compromise to the accuracy.\n",
        "Let's see how it's done..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmm47qvuU8Ly",
        "colab_type": "text"
      },
      "source": [
        "We will be working with the keras implementation.\n",
        "So importing the required setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0WbDznrQJVY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6db15b7e-8596-4773-ec3b-8cbb59dd659e"
      },
      "source": [
        "pip install -q tensorflow-model-optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 174kB 4.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 15.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JB8iOQaQUJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5yBsmhZVRy3",
        "colab_type": "text"
      },
      "source": [
        "Now, training the MNIST dataset based model without pruning.\n",
        "This will be a less complex model to start with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V86LH10QZ2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "6339712f-6eb9-4abc-e3b6-10c82aeefb4d"
      },
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Define the model architecture.\n",
        "model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=5,\n",
        "  validation_split=0.25,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.3320 - accuracy: 0.9076 - val_loss: 0.1906 - val_accuracy: 0.9459\n",
            "Epoch 2/5\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1432 - accuracy: 0.9585 - val_loss: 0.1212 - val_accuracy: 0.9652\n",
            "Epoch 3/5\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0986 - accuracy: 0.9723 - val_loss: 0.1024 - val_accuracy: 0.9699\n",
            "Epoch 4/5\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0786 - accuracy: 0.9777 - val_loss: 0.0955 - val_accuracy: 0.9716\n",
            "Epoch 5/5\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0653 - accuracy: 0.9806 - val_loss: 0.0828 - val_accuracy: 0.9754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f010a223710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrQILPMdVn5W",
        "colab_type": "text"
      },
      "source": [
        "We will now be calculating the baseline accuracy and saving the model to use its weight as a pre-trained for the later use while pruning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k18AaSPpQpL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2386c48d-8501-4eca-d38e-c3026320c4b2"
      },
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "\n",
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
        "print('Saved baseline model to:', keras_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline test accuracy: 0.9771000146865845\n",
            "Saved baseline model to: /tmp/tmpayddxtd7.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myj_IZDqVmSm",
        "colab_type": "text"
      },
      "source": [
        "Here, we will be importing the built-in tensoflow optimization  module as tfmot for pruning.\n",
        "Then we will be applyonh sparsity(removing multiple weights and interconnections) on to the model starting for 40% to 85%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FrDKfMVQvg_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "319afa91-ae80-4800-96e0-e61c120ed0f6"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 4 epochs.\n",
        "batch_size = 128\n",
        "epochs = 4\n",
        "validation_split = 0.25 # 25% of training set will be used for validation set. \n",
        "\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs #defining the end step to erdicate the chances of model exceding the limit of batch size\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.40,\n",
        "                                                               final_sparsity=0.85,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "#here we have taken the model defined above, and applied the pruning_parameters to it.\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_reshape_ (None, 28, 28, 1)         1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_2 (None, 26, 26, 12)        230       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 2028)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_2  (None, 10)                40572     \n",
            "=================================================================\n",
            "Total params: 40,805\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 20,395\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddic9Z5PXO5U",
        "colab_type": "text"
      },
      "source": [
        "Here, if we look at the results the total parameters have reduced from 40,805 to 20,410. Which implies the speed or performance of the model increases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cubRItbYUb5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Fine tune with pruning for two epochs.\n",
        "\n",
        "`tfmot.sparsity.keras.UpdatePruningStep` is required during training,\n",
        "and `tfmot.sparsity.keras.PruningSummaries` provides logs for tracking progress and debugging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEkShUk7Q2iL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "742ec902-be88-4289-b4dc-d4a365c9d302"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "  \n",
        "model_for_pruning.fit(train_images, train_labels,\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
        "                  callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.0740 - accuracy: 0.9784 - val_loss: 0.1024 - val_accuracy: 0.9696\n",
            "Epoch 2/4\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0666 - accuracy: 0.9800 - val_loss: 0.1079 - val_accuracy: 0.9683\n",
            "Epoch 3/4\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0651 - accuracy: 0.9808 - val_loss: 0.1025 - val_accuracy: 0.9684\n",
            "Epoch 4/4\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.0658 - accuracy: 0.9805 - val_loss: 0.1050 - val_accuracy: 0.9681\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0057437978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37LS0K2xQ6jO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dde28ac2-19ff-4805-f67f-8d94d8b3eda5"
      },
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy) \n",
        "print('Pruned test accuracy:', model_for_pruning_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline test accuracy: 0.9771000146865845\n",
            "Pruned test accuracy: 0.9733999967575073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPZ_AkqAXpQb",
        "colab_type": "text"
      },
      "source": [
        "With comparison of the baseline and pruned accuracy we can make out the fact that the pruning did not have a great impact on accuracy of the model, but as we have seen earlier the model's performance has increased as the parameters have reduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HGiTwIYY924",
        "colab_type": "text"
      },
      "source": [
        "Now, let's see a method through which we can reduce the size of the model namely we are going to gzip the model now to reduce it size.\n",
        "Both `tfmot.sparsity.keras.strip_pruning` and applying a standard compression algorithm (e.g. via gzip) are necessary to see the compression benefits of pruning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGoakBuZZkDV",
        "colab_type": "text"
      },
      "source": [
        "Creating a compressible model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tDgG-5zRGFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "add59dce-2015-4285-ee93-f4b4cbb58c68"
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmpw3dtf_8l.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvROR-yCZ-eX",
        "colab_type": "text"
      },
      "source": [
        " Creating a compressible model for TFLite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHNf2ACNRKfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b81391ab-ef6b-416c-d1ab-77158921cbcc"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "  f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned TFLite model to: /tmp/tmp3e_u6w8y.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvSBfFzPaIkB",
        "colab_type": "text"
      },
      "source": [
        "Creating an function to gzip the model and return the zipped model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsXhcYp5RONJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdY49HKKRY2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f9cd5547-150a-4b11-be92-c0002c154341"
      },
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped baseline Keras model: 77978.00 bytes\n",
            "Size of gzipped pruned Keras model: 25630.00 bytes\n",
            "Size of gzipped pruned TFlite model: 24403.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jmVSs0PaTt0",
        "colab_type": "text"
      },
      "source": [
        "Here, we see that we have reduced the size of the model from 77978 bytes to 25630 bytes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwtDI2zPajph",
        "colab_type": "text"
      },
      "source": [
        "The model size could be reduced to 10X further with the help of combining puring and quantisation together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jH7DQivTReQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}